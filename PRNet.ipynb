{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d20510e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PR_RUN_OPTIONS = {\n",
    "    'input': 'input',    # path to the input directory, where input images are stored\n",
    "    'output': 'output',  # path to the output directory, where results(obj,txt files) will be stored\n",
    "    'material': 'mat',   # path to the output directory, where material(mat files) will be stored\n",
    "    'gpu': -1,           # set gpu id, -1 for CPU\n",
    "    'isDlib': True,      # whether to use dlib for detecting face, default is True, if False, the input image should be cropped in advance\n",
    "    'is3d': True,       # whether to output 3D face(.obj). default save colors\n",
    "    'isMat': True,       # whether to save vertices,color,triangles as mat for matlab showing\n",
    "    'isKpt': False,      # whether to output key points(.txt)\n",
    "    'isPose': False,     # whether to output estimated pose(.txt)\n",
    "    'isShow': False,     # whether to show the results with opencv(need opencv)\n",
    "    'isImage': False,    # whether to save input image\n",
    "    'isFront': False,    # whether to frontalize vertices(mesh)\n",
    "    'isDepth': True,     # whether to output depth image\n",
    "    'isTexture': False,  # whether to save texture in obj file\n",
    "    'isMask': False,     # whether to set invisible pixels(due to self-occlusion) in texture as 0   \n",
    "    'isMesh': False,     # size of texture map, default is 256. need isTexture is True\n",
    "    'textureSize': 256,  # size of texture map, default is 256. need isTexture is True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa1fadc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from time import time\n",
    "import functools\n",
    "from math import cos, sin, atan2, asin\n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "\n",
    "import scipy.io as sio\n",
    "from scipy import ndimage\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import rescale, resize, estimate_transform, warp\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as tcl\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e899228",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3c63f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_asc(path, vertices):\n",
    "    '''\n",
    "    Args:\n",
    "        vertices: shape = (nver, 3)\n",
    "    '''\n",
    "    if path.split('.')[-1] == 'asc':\n",
    "        np.savetxt(path, vertices)\n",
    "    else:\n",
    "        np.savetxt(path + '.asc', vertices)\n",
    "\n",
    "\n",
    "def write_obj_with_colors(obj_name, vertices, triangles, colors):\n",
    "    ''' Save 3D face model with texture represented by colors.\n",
    "    Args:\n",
    "        obj_name: str\n",
    "        vertices: shape = (nver, 3)\n",
    "        colors: shape = (nver, 3)\n",
    "        triangles: shape = (ntri, 3)\n",
    "    '''\n",
    "    triangles = triangles.copy()\n",
    "    triangles += 1 # meshlab start with 1\n",
    "    \n",
    "    if obj_name.split('.')[-1] != 'obj':\n",
    "        obj_name = obj_name + '.obj'\n",
    "        \n",
    "    # write obj\n",
    "    with open(obj_name, 'w') as f:\n",
    "        \n",
    "        # write vertices & colors\n",
    "        for i in range(vertices.shape[0]):\n",
    "            # s = 'v {} {} {} \\n'.format(vertices[0,i], vertices[1,i], vertices[2,i])\n",
    "            s = 'v {} {} {} {} {} {}\\n'.format(vertices[i, 0], vertices[i, 1], vertices[i, 2], colors[i, 0], colors[i, 1], colors[i, 2])\n",
    "            f.write(s)\n",
    "\n",
    "        # write f: ver ind/ uv ind\n",
    "        [k, ntri] = triangles.shape\n",
    "        for i in range(triangles.shape[0]):\n",
    "            # s = 'f {} {} {}\\n'.format(triangles[i, 0], triangles[i, 1], triangles[i, 2])\n",
    "            s = 'f {} {} {}\\n'.format(triangles[i, 2], triangles[i, 1], triangles[i, 0])\n",
    "            f.write(s)\n",
    "\n",
    "\n",
    "def write_obj_with_texture(obj_name, vertices, triangles, texture, uv_coords):\n",
    "    ''' Save 3D face model with texture represented by texture map.\n",
    "    Ref: https://github.com/patrikhuber/eos/blob/bd00155ebae4b1a13b08bf5a991694d682abbada/include/eos/core/Mesh.hpp\n",
    "    Args:\n",
    "        obj_name: str\n",
    "        vertices: shape = (nver, 3)\n",
    "        triangles: shape = (ntri, 3)\n",
    "        texture: shape = (256,256,3)\n",
    "        uv_coords: shape = (nver, 3) max value<=1\n",
    "    '''\n",
    "    if obj_name.split('.')[-1] != 'obj':\n",
    "        obj_name = obj_name + '.obj'\n",
    "    mtl_name = obj_name.replace('.obj', '.mtl')\n",
    "    texture_name = obj_name.replace('.obj', '_texture.png')\n",
    "    \n",
    "    triangles = triangles.copy()\n",
    "    triangles += 1 # mesh lab start with 1\n",
    "    \n",
    "    # write obj\n",
    "    with open(obj_name, 'w') as f:\n",
    "        # first line: write mtlib(material library)\n",
    "        s = \"mtllib {}\\n\".format(os.path.abspath(mtl_name))\n",
    "        f.write(s)\n",
    "\n",
    "        # write vertices\n",
    "        for i in range(vertices.shape[0]):\n",
    "            s = 'v {} {} {}\\n'.format(vertices[i, 0], vertices[i, 1], vertices[i, 2])\n",
    "            f.write(s)\n",
    "        \n",
    "        # write uv coords\n",
    "        for i in range(uv_coords.shape[0]):\n",
    "            s = 'vt {} {}\\n'.format(uv_coords[i,0], 1 - uv_coords[i,1])\n",
    "            f.write(s)\n",
    "\n",
    "        f.write(\"usemtl FaceTexture\\n\")\n",
    "\n",
    "        # write f: ver ind/ uv ind\n",
    "        for i in range(triangles.shape[0]):\n",
    "            # s = 'f {}/{} {}/{} {}/{}\\n'.format(triangles[i,0], triangles[i,0], triangles[i,1], triangles[i,1], triangles[i,2], triangles[i,2])\n",
    "            s = 'f {}/{} {}/{} {}/{}\\n'.format(triangles[i,2], triangles[i,2], triangles[i,1], triangles[i,1], triangles[i,0], triangles[i,0])\n",
    "            f.write(s)\n",
    "\n",
    "    # write mtl\n",
    "    with open(mtl_name, 'w') as f:\n",
    "        f.write(\"newmtl FaceTexture\\n\")\n",
    "        s = 'map_Kd {}\\n'.format(os.path.abspath(texture_name)) # map to image\n",
    "        f.write(s)\n",
    "\n",
    "    # write texture as png\n",
    "    imsave(texture_name, texture)\n",
    "\n",
    "\n",
    "def write_obj_with_colors_texture(obj_name, vertices, colors, triangles, texture, uv_coords):\n",
    "    ''' Save 3D face model with texture. \n",
    "    Ref: https://github.com/patrikhuber/eos/blob/bd00155ebae4b1a13b08bf5a991694d682abbada/include/eos/core/Mesh.hpp\n",
    "    Args:\n",
    "        obj_name: str\n",
    "        vertices: shape = (nver, 3)\n",
    "        colors: shape = (nver, 3)\n",
    "        triangles: shape = (ntri, 3)\n",
    "        texture: shape = (256,256,3)\n",
    "        uv_coords: shape = (nver, 3) max value<=1\n",
    "    '''\n",
    "    if obj_name.split('.')[-1] != 'obj':\n",
    "        obj_name = obj_name + '.obj'\n",
    "    mtl_name = obj_name.replace('.obj', '.mtl')\n",
    "    texture_name = obj_name.replace('.obj', '_texture.png')\n",
    "    \n",
    "    triangles = triangles.copy()\n",
    "    triangles += 1 # mesh lab start with 1\n",
    "    \n",
    "    # write obj\n",
    "    with open(obj_name, 'w') as f:\n",
    "        # first line: write mtlib(material library)\n",
    "        s = \"mtllib {}\\n\".format(os.path.abspath(mtl_name))\n",
    "        f.write(s)\n",
    "\n",
    "        # write vertices\n",
    "        for i in range(vertices.shape[0]):\n",
    "            s = 'v {} {} {} {} {} {}\\n'.format(vertices[i, 0], vertices[i, 1], vertices[i, 2], colors[i, 0], colors[i, 1], colors[i, 2])\n",
    "            f.write(s)\n",
    "        \n",
    "        # write uv coords\n",
    "        for i in range(uv_coords.shape[0]):\n",
    "            s = 'vt {} {}\\n'.format(uv_coords[i,0], 1 - uv_coords[i,1])\n",
    "            f.write(s)\n",
    "\n",
    "        f.write(\"usemtl FaceTexture\\n\")\n",
    "\n",
    "        # write f: ver ind/ uv ind\n",
    "        for i in range(triangles.shape[0]):\n",
    "            # s = 'f {}/{} {}/{} {}/{}\\n'.format(triangles[i,0], triangles[i,0], triangles[i,1], triangles[i,1], triangles[i,2], triangles[i,2])\n",
    "            s = 'f {}/{} {}/{} {}/{}\\n'.format(triangles[i,2], triangles[i,2], triangles[i,1], triangles[i,1], triangles[i,0], triangles[i,0])\n",
    "            f.write(s)\n",
    "\n",
    "    # write mtl\n",
    "    with open(mtl_name, 'w') as f:\n",
    "        f.write(\"newmtl FaceTexture\\n\")\n",
    "        s = 'map_Kd {}\\n'.format(os.path.abspath(texture_name)) # map to image\n",
    "        f.write(s)\n",
    "\n",
    "    # write texture as png\n",
    "    imsave(texture_name, texture)\n",
    "    \n",
    "def get_visibility(vertices, triangles, h, w):\n",
    "    triangles = triangles.T\n",
    "    vertices_vis = vis_of_vertices(vertices.T, triangles, h, w)\n",
    "    vertices_vis = vertices_vis.astype(bool)\n",
    "    for k in range(2):\n",
    "        tri_vis = vertices_vis[triangles[0,:]] | vertices_vis[triangles[1,:]] | vertices_vis[triangles[2,:]]\n",
    "        ind = triangles[:, tri_vis]\n",
    "        vertices_vis[ind] = True\n",
    "    # for k in range(2):\n",
    "    #     tri_vis = vertices_vis[triangles[0,:]] & vertices_vis[triangles[1,:]] & vertices_vis[triangles[2,:]]\n",
    "    #     ind = triangles[:, tri_vis]\n",
    "    #     vertices_vis[ind] = True\n",
    "    vertices_vis = vertices_vis.astype(np.float32)  #1 for visible and 0 for non-visible\n",
    "    return vertices_vis\n",
    "\n",
    "def get_uv_mask(vertices_vis, triangles, uv_coords, h, w, resolution):\n",
    "    triangles = triangles.T\n",
    "    vertices_vis = vertices_vis.astype(np.float32)\n",
    "    uv_mask = render_texture(uv_coords.T, vertices_vis[np.newaxis, :], triangles, resolution, resolution, 1)\n",
    "    uv_mask = np.squeeze(uv_mask > 0)\n",
    "    uv_mask = ndimage.binary_closing(uv_mask)\n",
    "    uv_mask = ndimage.binary_erosion(uv_mask, structure = np.ones((4,4)))  \n",
    "    uv_mask = ndimage.binary_closing(uv_mask)\n",
    "    uv_mask = ndimage.binary_erosion(uv_mask, structure = np.ones((4,4)))  \n",
    "    uv_mask = ndimage.binary_erosion(uv_mask, structure = np.ones((4,4)))  \n",
    "    uv_mask = ndimage.binary_erosion(uv_mask, structure = np.ones((4,4)))  \n",
    "    uv_mask = uv_mask.astype(np.float32)\n",
    "\n",
    "    return np.squeeze(uv_mask)\n",
    "\n",
    "def get_depth_image(vertices, triangles, h, w, isShow = False):\n",
    "    z = vertices[:, 2:]\n",
    "    if isShow:\n",
    "        z = z/max(z)\n",
    "    depth_image = render_texture(vertices.T, z.T, triangles.T, h, w, 1)\n",
    "    return np.squeeze(depth_image)\n",
    "\n",
    "def frontalize(vertices):\n",
    "    canonical_vertices = np.load('Data/uv-data/canonical_vertices.npy')\n",
    "\n",
    "    vertices_homo = np.hstack((vertices, np.ones([vertices.shape[0],1]))) #n x 4\n",
    "    P = np.linalg.lstsq(vertices_homo, canonical_vertices)[0].T # Affine matrix. 3 x 4\n",
    "    front_vertices = vertices_homo.dot(P.T)\n",
    "\n",
    "    return front_vertices\n",
    "\n",
    "\n",
    "def isRotationMatrix(R):\n",
    "    ''' checks if a matrix is a valid rotation matrix(whether orthogonal or not)\n",
    "    '''\n",
    "    Rt = np.transpose(R)\n",
    "    shouldBeIdentity = np.dot(Rt, R)\n",
    "    I = np.identity(3, dtype = R.dtype)\n",
    "    n = np.linalg.norm(I - shouldBeIdentity)\n",
    "    return n < 1e-6\n",
    "\n",
    "\n",
    "def matrix2angle(R):\n",
    "    ''' compute three Euler angles from a Rotation Matrix. Ref: http://www.gregslabaugh.net/publications/euler.pdf\n",
    "    Args:\n",
    "        R: (3,3). rotation matrix\n",
    "    Returns:\n",
    "        x: yaw\n",
    "        y: pitch\n",
    "        z: roll\n",
    "    '''\n",
    "    # assert(isRotationMatrix(R))\n",
    "\n",
    "    if R[2,0] !=1 or R[2,0] != -1:\n",
    "        x = asin(R[2,0])\n",
    "        y = atan2(R[2,1]/cos(x), R[2,2]/cos(x))\n",
    "        z = atan2(R[1,0]/cos(x), R[0,0]/cos(x))\n",
    "        \n",
    "    else:# Gimbal lock\n",
    "        z = 0 #can be anything\n",
    "        if R[2,0] == -1:\n",
    "            x = np.pi/2\n",
    "            y = z + atan2(R[0,1], R[0,2])\n",
    "        else:\n",
    "            x = -np.pi/2\n",
    "            y = -z + atan2(-R[0,1], -R[0,2])\n",
    "\n",
    "    return x, y, z\n",
    "\n",
    "\n",
    "def P2sRt(P):\n",
    "    ''' decompositing camera matrix P. \n",
    "    Args: \n",
    "        P: (3, 4). Affine Camera Matrix.\n",
    "    Returns:\n",
    "        s: scale factor.\n",
    "        R: (3, 3). rotation matrix.\n",
    "        t2d: (2,). 2d translation. \n",
    "    '''\n",
    "    t2d = P[:2, 3]\n",
    "    R1 = P[0:1, :3]\n",
    "    R2 = P[1:2, :3]\n",
    "    s = (np.linalg.norm(R1) + np.linalg.norm(R2))/2.0\n",
    "    r1 = R1/np.linalg.norm(R1)\n",
    "    r2 = R2/np.linalg.norm(R2)\n",
    "    r3 = np.cross(r1, r2)\n",
    "\n",
    "    R = np.concatenate((r1, r2, r3), 0)\n",
    "    return s, R, t2d\n",
    "\n",
    "\n",
    "def compute_similarity_transform(points_static, points_to_transform):\n",
    "    #http://nghiaho.com/?page_id=671\n",
    "    p0 = np.copy(points_static).T\n",
    "    p1 = np.copy(points_to_transform).T\n",
    "\n",
    "    t0 = -np.mean(p0, axis=1).reshape(3,1)\n",
    "    t1 = -np.mean(p1, axis=1).reshape(3,1)\n",
    "    t_final = t1 -t0\n",
    "\n",
    "    p0c = p0+t0\n",
    "    p1c = p1+t1\n",
    "\n",
    "    covariance_matrix = p0c.dot(p1c.T)\n",
    "    U,S,V = np.linalg.svd(covariance_matrix)\n",
    "    R = U.dot(V)\n",
    "    if np.linalg.det(R) < 0:\n",
    "        R[:,2] *= -1\n",
    "\n",
    "    rms_d0 = np.sqrt(np.mean(np.linalg.norm(p0c, axis=0)**2))\n",
    "    rms_d1 = np.sqrt(np.mean(np.linalg.norm(p1c, axis=0)**2))\n",
    "\n",
    "    s = (rms_d0/rms_d1)\n",
    "    P = np.c_[s*np.eye(3).dot(R), t_final]\n",
    "    return P\n",
    "\n",
    "def estimate_pose(vertices):\n",
    "    canonical_vertices = np.load('Data/uv-data/canonical_vertices.npy')\n",
    "    P = compute_similarity_transform(vertices, canonical_vertices)\n",
    "    _,R,_ = P2sRt(P) # decompose affine matrix to s, R, t\n",
    "    pose = matrix2angle(R) \n",
    "\n",
    "    return P, pose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549a8116",
   "metadata": {},
   "source": [
    "### API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26fe599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visibility(vertices, triangles, h, w):\n",
    "    triangles = triangles.T\n",
    "    vertices_vis = vis_of_vertices(vertices.T, triangles, h, w)\n",
    "    vertices_vis = vertices_vis.astype(bool)\n",
    "    for k in range(2):\n",
    "        tri_vis = vertices_vis[triangles[0,:]] | vertices_vis[triangles[1,:]] | vertices_vis[triangles[2,:]]\n",
    "        ind = triangles[:, tri_vis]\n",
    "        vertices_vis[ind] = True\n",
    "    # for k in range(2):\n",
    "    #     tri_vis = vertices_vis[triangles[0,:]] & vertices_vis[triangles[1,:]] & vertices_vis[triangles[2,:]]\n",
    "    #     ind = triangles[:, tri_vis]\n",
    "    #     vertices_vis[ind] = True\n",
    "    vertices_vis = vertices_vis.astype(np.float32)  #1 for visible and 0 for non-visible\n",
    "    return vertices_vis\n",
    "\n",
    "def get_uv_mask(vertices_vis, triangles, uv_coords, h, w, resolution):\n",
    "    triangles = triangles.T\n",
    "    vertices_vis = vertices_vis.astype(np.float32)\n",
    "    uv_mask = render_texture(uv_coords.T, vertices_vis[np.newaxis, :], triangles, resolution, resolution, 1)\n",
    "    uv_mask = np.squeeze(uv_mask > 0)\n",
    "    uv_mask = ndimage.binary_closing(uv_mask)\n",
    "    uv_mask = ndimage.binary_erosion(uv_mask, structure = np.ones((4,4)))  \n",
    "    uv_mask = ndimage.binary_closing(uv_mask)\n",
    "    uv_mask = ndimage.binary_erosion(uv_mask, structure = np.ones((4,4)))  \n",
    "    uv_mask = ndimage.binary_erosion(uv_mask, structure = np.ones((4,4)))  \n",
    "    uv_mask = ndimage.binary_erosion(uv_mask, structure = np.ones((4,4)))  \n",
    "    uv_mask = uv_mask.astype(np.float32)\n",
    "\n",
    "    return np.squeeze(uv_mask)\n",
    "\n",
    "def get_depth_image(vertices, triangles, h, w, isShow = False):\n",
    "    z = vertices[:, 2:]\n",
    "    if isShow:\n",
    "        z = z/max(z)\n",
    "    depth_image = render_texture(vertices.T, z.T, triangles.T, h, w, 1)\n",
    "    return np.squeeze(depth_image)\n",
    "\n",
    "\n",
    "def isPointInTri(point, tri_points):\n",
    "    ''' Judge whether the point is in the triangle\n",
    "    Method:\n",
    "        http://blackpawn.com/texts/pointinpoly/\n",
    "    Args:\n",
    "        point: [u, v] or [x, y] \n",
    "        tri_points: three vertices(2d points) of a triangle. 2 coords x 3 vertices\n",
    "    Returns:\n",
    "        bool: true for in triangle\n",
    "    '''\n",
    "    tp = tri_points\n",
    "\n",
    "    # vectors\n",
    "    v0 = tp[:,2] - tp[:,0]\n",
    "    v1 = tp[:,1] - tp[:,0]\n",
    "    v2 = point - tp[:,0]\n",
    "\n",
    "    # dot products\n",
    "    dot00 = np.dot(v0.T, v0)\n",
    "    dot01 = np.dot(v0.T, v1)\n",
    "    dot02 = np.dot(v0.T, v2)\n",
    "    dot11 = np.dot(v1.T, v1)\n",
    "    dot12 = np.dot(v1.T, v2)\n",
    "\n",
    "    # barycentric coordinates\n",
    "    if dot00*dot11 - dot01*dot01 == 0:\n",
    "        inverDeno = 0\n",
    "    else:\n",
    "        inverDeno = 1/(dot00*dot11 - dot01*dot01)\n",
    "\n",
    "    u = (dot11*dot02 - dot01*dot12)*inverDeno\n",
    "    v = (dot00*dot12 - dot01*dot02)*inverDeno\n",
    "\n",
    "    # check if point in triangle\n",
    "    return (u >= 0) & (v >= 0) & (u + v < 1)\n",
    "\n",
    "def get_point_weight(point, tri_points):\n",
    "    ''' Get the weights of the position\n",
    "    Methods: https://gamedev.stackexchange.com/questions/23743/whats-the-most-efficient-way-to-find-barycentric-coordinates\n",
    "     -m1.compute the area of the triangles formed by embedding the point P inside the triangle\n",
    "     -m2.Christer Ericson's book \"Real-Time Collision Detection\". faster, so I used this.\n",
    "    Args:\n",
    "        point: [u, v] or [x, y] \n",
    "        tri_points: three vertices(2d points) of a triangle. 2 coords x 3 vertices\n",
    "    Returns:\n",
    "        w0: weight of v0\n",
    "        w1: weight of v1\n",
    "        w2: weight of v3\n",
    "     '''\n",
    "    tp = tri_points\n",
    "    # vectors\n",
    "    v0 = tp[:,2] - tp[:,0]\n",
    "    v1 = tp[:,1] - tp[:,0]\n",
    "    v2 = point - tp[:,0]\n",
    "\n",
    "    # dot products\n",
    "    dot00 = np.dot(v0.T, v0)\n",
    "    dot01 = np.dot(v0.T, v1)\n",
    "    dot02 = np.dot(v0.T, v2)\n",
    "    dot11 = np.dot(v1.T, v1)\n",
    "    dot12 = np.dot(v1.T, v2)\n",
    "\n",
    "    # barycentric coordinates\n",
    "    if dot00*dot11 - dot01*dot01 == 0:\n",
    "        inverDeno = 0\n",
    "    else:\n",
    "        inverDeno = 1/(dot00*dot11 - dot01*dot01)\n",
    "\n",
    "    u = (dot11*dot02 - dot01*dot12)*inverDeno\n",
    "    v = (dot00*dot12 - dot01*dot02)*inverDeno\n",
    "\n",
    "    w0 = 1 - u - v\n",
    "    w1 = v\n",
    "    w2 = u\n",
    "\n",
    "    return w0, w1, w2\n",
    "\n",
    "\n",
    "def render_texture(vertices, colors, triangles, h, w, c = 3):\n",
    "    ''' render mesh by z buffer\n",
    "    Args:\n",
    "        vertices: 3 x nver\n",
    "        colors: 3 x nver\n",
    "        triangles: 3 x ntri\n",
    "        h: height\n",
    "        w: width    \n",
    "    '''\n",
    "    # initial \n",
    "    image = np.zeros((h, w, c))\n",
    "\n",
    "    depth_buffer = np.zeros([h, w]) - 999999.\n",
    "    # triangle depth: approximate the depth to the average value of z in each vertex(v0, v1, v2), since the vertices are closed to each other\n",
    "    tri_depth = (vertices[2, triangles[0,:]] + vertices[2,triangles[1,:]] + vertices[2, triangles[2,:]])/3. \n",
    "    tri_tex = (colors[:, triangles[0,:]] + colors[:,triangles[1,:]] + colors[:, triangles[2,:]])/3.\n",
    "\n",
    "    for i in range(triangles.shape[1]):\n",
    "        tri = triangles[:, i] # 3 vertex indices\n",
    "\n",
    "        # the inner bounding box\n",
    "        umin = max(int(np.ceil(np.min(vertices[0,tri]))), 0)\n",
    "        umax = min(int(np.floor(np.max(vertices[0,tri]))), w-1)\n",
    "\n",
    "        vmin = max(int(np.ceil(np.min(vertices[1,tri]))), 0)\n",
    "        vmax = min(int(np.floor(np.max(vertices[1,tri]))), h-1)\n",
    "\n",
    "        if umax<umin or vmax<vmin:\n",
    "            continue\n",
    "\n",
    "        for u in range(umin, umax+1):\n",
    "            for v in range(vmin, vmax+1):\n",
    "                if tri_depth[i] > depth_buffer[v, u] and isPointInTri([u,v], vertices[:2, tri]): \n",
    "                    depth_buffer[v, u] = tri_depth[i]\n",
    "                    image[v, u, :] = tri_tex[:, i]\n",
    "    return image\n",
    "\n",
    "\n",
    "def map_texture(src_image, src_vertices, dst_vertices, dst_triangle_buffer, triangles, h, w, c = 3, mapping_type = 'bilinear'):\n",
    "    '''\n",
    "    Args:\n",
    "        triangles: 3 x ntri\n",
    "\n",
    "        # src\n",
    "        src_image: height x width x nchannels\n",
    "        src_vertices: 3 x nver\n",
    "        \n",
    "        # dst\n",
    "        dst_vertices: 3 x nver\n",
    "        dst_triangle_buffer: height x width. the triangle index of each pixel in dst image\n",
    "\n",
    "    Returns:\n",
    "        dst_image: height x width x nchannels\n",
    "\n",
    "    '''\n",
    "    [sh, sw, sc] = src_image.shape\n",
    "    dst_image = np.zeros((h, w, c))\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            tri_ind = dst_triangle_buffer[y,x]\n",
    "            if tri_ind < 0: # no tri in dst image\n",
    "                continue \n",
    "            #if src_triangles_vis[tri_ind]: # the corresponding triangle in src image is invisible\n",
    "            #   continue\n",
    "            \n",
    "            # then. For this triangle index, map corresponding pixels(in triangles) in src image to dst image\n",
    "            # Two Methods:\n",
    "            # M1. Calculate the corresponding affine matrix from src triangle to dst triangle. Then find the corresponding src position of this dst pixel.\n",
    "            # -- ToDo\n",
    "            # M2. Calculate the relative position of three vertices in dst triangle, then find the corresponding src position relative to three src vertices.\n",
    "            tri = triangles[:, tri_ind]\n",
    "            # dst weight, here directly use the center to approximate because the tri is small\n",
    "            # if tri_ind < 366:\n",
    "                # print tri_ind\n",
    "            w0, w1, w2 = get_point_weight([x, y], dst_vertices[:2, tri])\n",
    "            # else:\n",
    "            #     w0 = w1 = w2 = 1./3\n",
    "            # src\n",
    "            src_texel = w0*src_vertices[:2, tri[0]] + w1*src_vertices[:2, tri[1]] + w2*src_vertices[:2, tri[2]] #\n",
    "# \n",
    "            if src_texel[0] < 0 or src_texel[0]> sw-1 or src_texel[1]<0 or src_texel[1] > sh-1:\n",
    "                dst_image[y, x, :] = 0\n",
    "                continue\n",
    "            # As the coordinates of the transformed pixel in the image will most likely not lie on a texel, we have to choose how to\n",
    "            # calculate the pixel colors depending on the next texels\n",
    "            # there are three different texture interpolation methods: area, bilinear and nearest neighbour\n",
    "            # print y, x, src_texel\n",
    "            # nearest neighbour \n",
    "            if mapping_type == 'nearest':\n",
    "                dst_image[y, x, :] = src_image[int(round(src_texel[1])), int(round(src_texel[0])), :]\n",
    "            # bilinear\n",
    "            elif mapping_type == 'bilinear':\n",
    "                # next 4 pixels\n",
    "                ul = src_image[int(np.floor(src_texel[1])), int(np.floor(src_texel[0])), :]\n",
    "                ur = src_image[int(np.floor(src_texel[1])), int(np.ceil(src_texel[0])), :]\n",
    "                dl = src_image[int(np.ceil(src_texel[1])), int(np.floor(src_texel[0])), :]\n",
    "                dr = src_image[int(np.ceil(src_texel[1])), int(np.ceil(src_texel[0])), :]\n",
    "\n",
    "                yd = src_texel[1] - np.floor(src_texel[1])\n",
    "                xd = src_texel[0] - np.floor(src_texel[0])\n",
    "                dst_image[y, x, :] = ul*(1-xd)*(1-yd) + ur*xd*(1-yd) + dl*(1-xd)*yd + dr*xd*yd\n",
    "                \n",
    "    return dst_image\n",
    "\n",
    "\n",
    "def get_depth_buffer(vertices, triangles, h, w):\n",
    "    '''\n",
    "    Args:\n",
    "        vertices: 3 x nver\n",
    "        triangles: 3 x ntri\n",
    "        h: height\n",
    "        w: width\n",
    "    Returns:\n",
    "        depth_buffer: height x width\n",
    "    ToDo:\n",
    "        whether to add x, y by 0.5? the center of the pixel?\n",
    "        m3. like somewhere is wrong\n",
    "    # Each triangle has 3 vertices & Each vertex has 3 coordinates x, y, z.\n",
    "    # Here, the bigger the z, the fronter the point.\n",
    "    '''\n",
    "    # initial \n",
    "    depth_buffer = np.zeros([h, w]) - 999999. #+ np.min(vertices[2,:]) - 999999. # set the initial z to the farest position\n",
    "\n",
    "    ## calculate the depth(z) of each triangle\n",
    "    #-m1. z = the center of shpere(through 3 vertices)\n",
    "    #center3d = (vertices[:, triangles[0,:]] + vertices[:,triangles[1,:]] + vertices[:, triangles[2,:]])/3.\n",
    "    #tri_depth = np.sum(center3d**2, axis = 0)\n",
    "    #-m2. z = the center of z(v0, v1, v2)\n",
    "    tri_depth = (vertices[2, triangles[0,:]] + vertices[2,triangles[1,:]] + vertices[2, triangles[2,:]])/3.\n",
    "    \n",
    "    for i in range(triangles.shape[1]):\n",
    "        tri = triangles[:, i] # 3 vertex indices\n",
    "\n",
    "        # the inner bounding box\n",
    "        umin = max(int(np.ceil(np.min(vertices[0,tri]))), 0)\n",
    "        umax = min(int(np.floor(np.max(vertices[0,tri]))), w-1)\n",
    "\n",
    "        vmin = max(int(np.ceil(np.min(vertices[1,tri]))), 0)\n",
    "        vmax = min(int(np.floor(np.max(vertices[1,tri]))), h-1)\n",
    "\n",
    "        if umax<umin or vmax<vmin:\n",
    "            continue\n",
    "\n",
    "        for u in range(umin, umax+1):\n",
    "            for v in range(vmin, vmax+1):\n",
    "                #-m3. calculate the accurate depth(z) of each pixel by barycentric weights\n",
    "                #w0, w1, w2 = weightsOfpoint([u,v], vertices[:2, tri])\n",
    "                #tri_depth = w0*vertices[2,tri[0]] + w1*vertices[2,tri[1]] + w2*vertices[2,tri[2]]\n",
    "                if tri_depth[i] > depth_buffer[v, u]: # and is_pointIntri([u,v], vertices[:2, tri]): \n",
    "                    depth_buffer[v, u] = tri_depth[i]\n",
    "\n",
    "    return depth_buffer\n",
    "\n",
    "\n",
    "def get_triangle_buffer(vertices, triangles, h, w):\n",
    "    '''\n",
    "    Args:\n",
    "        vertices: 3 x nver\n",
    "        triangles: 3 x ntri\n",
    "        h: height\n",
    "        w: width\n",
    "    Returns:\n",
    "        depth_buffer: height x width\n",
    "    ToDo:\n",
    "        whether to add x, y by 0.5? the center of the pixel?\n",
    "        m3. like somewhere is wrong\n",
    "    # Each triangle has 3 vertices & Each vertex has 3 coordinates x, y, z.\n",
    "    # Here, the bigger the z, the fronter the point.\n",
    "    '''\n",
    "    # initial \n",
    "    depth_buffer = np.zeros([h, w]) - 999999. #+ np.min(vertices[2,:]) - 999999. # set the initial z to the farest position\n",
    "    triangle_buffer = np.zeros_like(depth_buffer, dtype = np.int32) - 1 # if -1, the pixel has no triangle correspondance\n",
    "\n",
    "    ## calculate the depth(z) of each triangle\n",
    "    #-m1. z = the center of shpere(through 3 vertices)\n",
    "    #center3d = (vertices[:, triangles[0,:]] + vertices[:,triangles[1,:]] + vertices[:, triangles[2,:]])/3.\n",
    "    #tri_depth = np.sum(center3d**2, axis = 0)\n",
    "    #-m2. z = the center of z(v0, v1, v2)\n",
    "    tri_depth = (vertices[2, triangles[0,:]] + vertices[2,triangles[1,:]] + vertices[2, triangles[2,:]])/3.\n",
    "    \n",
    "    for i in range(triangles.shape[1]):\n",
    "        tri = triangles[:, i] # 3 vertex indices\n",
    "\n",
    "        # the inner bounding box\n",
    "        umin = max(int(np.ceil(np.min(vertices[0,tri]))), 0)\n",
    "        umax = min(int(np.floor(np.max(vertices[0,tri]))), w-1)\n",
    "\n",
    "        vmin = max(int(np.ceil(np.min(vertices[1,tri]))), 0)\n",
    "        vmax = min(int(np.floor(np.max(vertices[1,tri]))), h-1)\n",
    "\n",
    "        if umax<umin or vmax<vmin:\n",
    "            continue\n",
    "\n",
    "        for u in range(umin, umax+1):\n",
    "            for v in range(vmin, vmax+1):\n",
    "                #-m3. calculate the accurate depth(z) of each pixel by barycentric weights\n",
    "                #w0, w1, w2 = weightsOfpoint([u,v], vertices[:2, tri])\n",
    "                #tri_depth = w0*vertices[2,tri[0]] + w1*vertices[2,tri[1]] + w2*vertices[2,tri[2]]\n",
    "                if tri_depth[i] > depth_buffer[v, u] and isPointInTri([u,v], vertices[:2, tri]): \n",
    "                    depth_buffer[v, u] = tri_depth[i]\n",
    "                    triangle_buffer[v, u] = i\n",
    "\n",
    "    return triangle_buffer\n",
    "\n",
    "\n",
    "def vis_of_vertices(vertices, triangles, h, w, depth_buffer = None):\n",
    "    '''\n",
    "    Args:\n",
    "        vertices: 3 x nver\n",
    "        triangles: 3 x ntri\n",
    "        depth_buffer: height x width\n",
    "    Returns:\n",
    "        vertices_vis: nver. the visibility of each vertex\n",
    "    '''\n",
    "    if depth_buffer == None:\n",
    "        depth_buffer = get_depth_buffer(vertices, triangles, h, w)\n",
    "\n",
    "    vertices_vis = np.zeros(vertices.shape[1], dtype = bool)\n",
    "    \n",
    "    depth_tmp = np.zeros_like(depth_buffer) - 99999\n",
    "    for i in range(vertices.shape[1]):\n",
    "        vertex = vertices[:, i]\n",
    "\n",
    "        if np.floor(vertex[0]) < 0 or np.ceil(vertex[0]) > w-1 or np.floor(vertex[1]) < 0 or np.ceil(vertex[1]) > h-1:\n",
    "            continue        \n",
    "        \n",
    "        # bilinear interp \n",
    "        # ul = depth_buffer[int(np.floor(vertex[1])), int(np.floor(vertex[0]))]\n",
    "        # ur = depth_buffer[int(np.floor(vertex[1])), int(np.ceil(vertex[0]))]\n",
    "        # dl = depth_buffer[int(np.ceil(vertex[1])), int(np.floor(vertex[0]))]\n",
    "        # dr = depth_buffer[int(np.ceil(vertex[1])), int(np.ceil(vertex[0]))]\n",
    "        \n",
    "        # yd = vertex[1] - np.floor(vertex[1])\n",
    "        # xd = vertex[0] - np.floor(vertex[0])\n",
    "\n",
    "        # vertex_depth = ul*(1-xd)*(1-yd) + ur*xd*(1-yd) + dl*(1-xd)*yd + dr*xd*yd\n",
    "        \n",
    "        # nearest\n",
    "        px = int(np.round(vertex[0]))\n",
    "        py = int(np.round(vertex[1]))\n",
    "\n",
    "        # if (vertex[2] > depth_buffer[ul[0], ul[1]]) & (vertex[2] > depth_buffer[ur[0], ur[1]]) & (vertex[2] > depth_buffer[dl[0], dl[1]]) & (vertex[2] > depth_buffer[dr[0], dr[1]]):\n",
    "        if vertex[2] < depth_tmp[py, px]:\n",
    "            continue\n",
    "        \n",
    "        # if vertex[2] > depth_buffer[py, px]:\n",
    "        #     vertices_vis[i] = True\n",
    "        #     depth_tmp[py, px] = vertex[2]\n",
    "        # elif np.abs(vertex[2] - depth_buffer[py, px]) < 1:\n",
    "        #     vertices_vis[i] = True\n",
    "\n",
    "        threshold = 2 # need to be optimized.\n",
    "        if np.abs(vertex[2] - depth_buffer[py, px]) < threshold:\n",
    "        # if np.abs(vertex[2] - vertex_depth) < threshold:\n",
    "            vertices_vis[i] = True\n",
    "            depth_tmp[py, px] = vertex[2]\n",
    "\n",
    "    return vertices_vis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58f305e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resBlock(x, num_outputs, kernel_size = 4, stride=1, activation_fn=tf.nn.relu, normalizer_fn=tcl.batch_norm, scope=None):\n",
    "    assert num_outputs%2==0 #num_outputs must be divided by channel_factor(2 here)\n",
    "    with tf.variable_scope(scope, 'resBlock'):\n",
    "        shortcut = x\n",
    "        if stride != 1 or x.get_shape()[3] != num_outputs:\n",
    "            shortcut = tcl.conv2d(shortcut, num_outputs, kernel_size=1, stride=stride, \n",
    "                        activation_fn=None, normalizer_fn=None, scope='shortcut')\n",
    "        x = tcl.conv2d(x, num_outputs/2, kernel_size=1, stride=1, padding='SAME')\n",
    "        x = tcl.conv2d(x, num_outputs/2, kernel_size=kernel_size, stride=stride, padding='SAME')\n",
    "        x = tcl.conv2d(x, num_outputs, kernel_size=1, stride=1, activation_fn=None, padding='SAME', normalizer_fn=None)\n",
    "\n",
    "        x += shortcut       \n",
    "        x = normalizer_fn(x)\n",
    "        x = activation_fn(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "class resfcn256(object):\n",
    "    def __init__(self, resolution_inp = 256, resolution_op = 256, channel = 3, name = 'resfcn256'):\n",
    "        self.name = name\n",
    "        self.channel = channel\n",
    "        self.resolution_inp = resolution_inp\n",
    "        self.resolution_op = resolution_op\n",
    "\n",
    "    def __call__(self, x, is_training = True):\n",
    "        with tf.variable_scope(self.name, reuse=True) as scope:\n",
    "            with arg_scope([tcl.batch_norm], is_training=is_training, scale=True):\n",
    "                with arg_scope([tcl.conv2d, tcl.conv2d_transpose], activation_fn=tf.nn.relu, \n",
    "                                     normalizer_fn=tcl.batch_norm, \n",
    "                                     biases_initializer=None, \n",
    "                                     padding='SAME',\n",
    "                                     weights_regularizer=tcl.l2_regularizer(0.0002)):\n",
    "                    size = 16  \n",
    "                    # x: s x s x 3\n",
    "                    se = tcl.conv2d(x, num_outputs=size, kernel_size=4, stride=1) # 256 x 256 x 16\n",
    "                    se = resBlock(se, num_outputs=size * 2, kernel_size=4, stride=2) # 128 x 128 x 32\n",
    "                    se = resBlock(se, num_outputs=size * 2, kernel_size=4, stride=1) # 128 x 128 x 32\n",
    "                    se = resBlock(se, num_outputs=size * 4, kernel_size=4, stride=2) # 64 x 64 x 64\n",
    "                    se = resBlock(se, num_outputs=size * 4, kernel_size=4, stride=1) # 64 x 64 x 64\n",
    "                    se = resBlock(se, num_outputs=size * 8, kernel_size=4, stride=2) # 32 x 32 x 128\n",
    "                    se = resBlock(se, num_outputs=size * 8, kernel_size=4, stride=1) # 32 x 32 x 128\n",
    "                    se = resBlock(se, num_outputs=size * 16, kernel_size=4, stride=2) # 16 x 16 x 256\n",
    "                    se = resBlock(se, num_outputs=size * 16, kernel_size=4, stride=1) # 16 x 16 x 256\n",
    "                    se = resBlock(se, num_outputs=size * 32, kernel_size=4, stride=2) # 8 x 8 x 512\n",
    "                    se = resBlock(se, num_outputs=size * 32, kernel_size=4, stride=1) # 8 x 8 x 512\n",
    "\n",
    "                    pd = tcl.conv2d_transpose(se, size * 32, 4, stride=1) # 8 x 8 x 512 \n",
    "                    pd = tcl.conv2d_transpose(pd, size * 16, 4, stride=2) # 16 x 16 x 256 \n",
    "                    pd = tcl.conv2d_transpose(pd, size * 16, 4, stride=1) # 16 x 16 x 256 \n",
    "                    pd = tcl.conv2d_transpose(pd, size * 16, 4, stride=1) # 16 x 16 x 256 \n",
    "                    pd = tcl.conv2d_transpose(pd, size * 8, 4, stride=2) # 32 x 32 x 128 \n",
    "                    pd = tcl.conv2d_transpose(pd, size * 8, 4, stride=1) # 32 x 32 x 128 \n",
    "                    pd = tcl.conv2d_transpose(pd, size * 8, 4, stride=1) # 32 x 32 x 128 \n",
    "                    pd = tcl.conv2d_transpose(pd, size * 4, 4, stride=2) # 64 x 64 x 64 \n",
    "                    pd = tcl.conv2d_transpose(pd, size * 4, 4, stride=1) # 64 x 64 x 64 \n",
    "                    pd = tcl.conv2d_transpose(pd, size * 4, 4, stride=1) # 64 x 64 x 64 \n",
    "                    \n",
    "                    pd = tcl.conv2d_transpose(pd, size * 2, 4, stride=2) # 128 x 128 x 32\n",
    "                    pd = tcl.conv2d_transpose(pd, size * 2, 4, stride=1) # 128 x 128 x 32\n",
    "                    pd = tcl.conv2d_transpose(pd, size, 4, stride=2) # 256 x 256 x 16\n",
    "                    pd = tcl.conv2d_transpose(pd, size, 4, stride=1) # 256 x 256 x 16\n",
    "\n",
    "                    pd = tcl.conv2d_transpose(pd, 3, 4, stride=1) # 256 x 256 x 3\n",
    "                    pd = tcl.conv2d_transpose(pd, 3, 4, stride=1) # 256 x 256 x 3\n",
    "                    pos = tcl.conv2d_transpose(pd, 3, 4, stride=1, activation_fn = tf.nn.sigmoid)#, padding='SAME', weights_initializer=tf.random_normal_initializer(0, 0.02))\n",
    "                                \n",
    "                    return pos\n",
    "    @property\n",
    "    def vars(self):\n",
    "        return [var for var in tf.global_variables() if self.name in var.name]\n",
    "\n",
    "\n",
    "class PosPrediction():\n",
    "    def __init__(self, resolution_inp = 256, resolution_op = 256): \n",
    "        # -- hyper settings\n",
    "        self.resolution_inp = resolution_inp\n",
    "        self.resolution_op = resolution_op\n",
    "        self.MaxPos = resolution_inp*1.1\n",
    "\n",
    "        # network type\n",
    "        self.network = resfcn256(self.resolution_inp, self.resolution_op)\n",
    "\n",
    "        # net forward\n",
    "        self.x = tf.placeholder(tf.float32, shape=[None, self.resolution_inp, self.resolution_inp, 3])  \n",
    "        self.x_op = self.network(self.x, is_training = False)\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True)))\n",
    "\n",
    "    def restore(self, model_path):        \n",
    "        tf.train.Saver(self.network.vars).restore(self.sess, model_path)\n",
    " \n",
    "    def predict(self, image):\n",
    "        pos = self.sess.run(self.x_op, \n",
    "                    feed_dict = {self.x: image[np.newaxis, :,:,:]})\n",
    "        pos = np.squeeze(pos)\n",
    "        return pos*self.MaxPos\n",
    "\n",
    "    def predict_batch(self, images):\n",
    "        pos = self.sess.run(self.x_op, \n",
    "                    feed_dict = {self.x: images})\n",
    "        return pos*self.MaxPos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b179bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRN:\n",
    "    ''' Joint 3D Face Reconstruction and Dense Alignment with Position Map Regression Network\n",
    "    Args:\n",
    "        is_dlib(bool, optional): If true, dlib is used for detecting faces.\n",
    "        prefix(str, optional): If run at another folder, the absolute path is needed to load the data.\n",
    "    '''\n",
    "    def __init__(self, is_dlib = False, prefix = '.'):\n",
    "\n",
    "            # resolution of input and output image size.\n",
    "        self.resolution_inp = 256\n",
    "        self.resolution_op = 256\n",
    "\n",
    "        #---- load detectors\n",
    "        if is_dlib:\n",
    "            detector_path = os.path.join(prefix, './data/net-data/mmod_human_face_detector.dat')\n",
    "            self.face_detector = dlib.cnn_face_detection_model_v1(detector_path)\n",
    "\n",
    "        #---- load PRN \n",
    "        self.pos_predictor = PosPrediction(self.resolution_inp)\n",
    "        self.pos_predictor.restore(prefix + '/data/net-data/256_256_resfcn256_weight')\n",
    "\n",
    "        # uv file\n",
    "        self.uv_kpt_ind = np.loadtxt(prefix + '/data/uv-data/uv_kpt_ind.txt').astype(np.int32) # 2 x 68 get kpt\n",
    "        self.face_ind = np.loadtxt(prefix + '/data/uv-data/face_ind.txt').astype(np.int32) # get valid vertices in the pos map\n",
    "        self.triangles = np.loadtxt(prefix + '/data/uv-data/triangles.txt').astype(np.int32) # ntri x 3\n",
    "        \n",
    "        self.uv_coords = self.generate_uv_coords()        \n",
    "\n",
    "    def generate_uv_coords(self):\n",
    "        resolution = self.resolution_op\n",
    "        uv_coords = np.meshgrid(range(resolution),range(resolution))\n",
    "        uv_coords = np.transpose(np.array(uv_coords), [1,2,0])\n",
    "        uv_coords = np.reshape(uv_coords, [resolution**2, -1]);\n",
    "        uv_coords = uv_coords[self.face_ind, :]\n",
    "        uv_coords = np.hstack((uv_coords[:,:2], np.zeros([uv_coords.shape[0], 1])))\n",
    "        return uv_coords\n",
    "\n",
    "    def dlib_detect(self, image):\n",
    "        return self.face_detector(image, 1)\n",
    "\n",
    "    def net_forward(self, image):\n",
    "        ''' The core of out method: regress the position map of a given image.\n",
    "        Args:\n",
    "            image: (256,256,3) array. value range: 0~1\n",
    "        Returns:\n",
    "            pos: the 3D position map. (256, 256, 3) array.\n",
    "        '''\n",
    "        return self.pos_predictor.predict(image)\n",
    "\n",
    "    def process(self, input, image_info = None):\n",
    "        ''' process image with crop operation.\n",
    "        Args:\n",
    "            input: (h,w,3) array or str(image path). image value range:1~255. \n",
    "            image_info(optional): the bounding box information of faces. if None, will use dlib to detect face. \n",
    "        Returns:\n",
    "            pos: the 3D position map. (256, 256, 3).\n",
    "        '''\n",
    "        if isinstance(input, str):\n",
    "            try:\n",
    "                image = imread(input)\n",
    "            except IOError:\n",
    "                print(\"error opening file: \", input)\n",
    "                return None\n",
    "        else:\n",
    "            image = input\n",
    "\n",
    "        if image.ndim < 3:\n",
    "            image = np.tile(image[:,:,np.newaxis], [1,1,3])\n",
    "\n",
    "        if image_info is not None:\n",
    "            if np.max(image_info.shape) > 4: # key points to get bounding box\n",
    "                kpt = image_info\n",
    "                if kpt.shape[0] > 3:\n",
    "                    kpt = kpt.T\n",
    "                left = np.min(kpt[0, :]); right = np.max(kpt[0, :]); \n",
    "                top = np.min(kpt[1,:]); bottom = np.max(kpt[1,:])\n",
    "            else:  # bounding box\n",
    "                bbox = image_info\n",
    "                left = bbox[0]; right = bbox[1]; top = bbox[2]; bottom = bbox[3]\n",
    "            old_size = (right - left + bottom - top)/2\n",
    "            center = np.array([right - (right - left) / 2.0, bottom - (bottom - top) / 2.0])\n",
    "            size = int(old_size*1.6)\n",
    "        else:\n",
    "            detected_faces = self.dlib_detect(image)\n",
    "            if len(detected_faces) == 0:\n",
    "                print('warning: no detected face')\n",
    "                return None,(0,0,0,0)\n",
    "\n",
    "            d = detected_faces[0].rect ## only use the first detected face (assume that each input image only contains one face)\n",
    "            left = d.left(); right = d.right(); top = d.top(); bottom = d.bottom()\n",
    "            old_size = (right - left + bottom - top)/2\n",
    "            center = np.array([right - (right - left) / 2.0, bottom - (bottom - top) / 2.0 + old_size*0.14])\n",
    "            size = int(old_size*1.58)\n",
    "            coor_face=(left,top,right,bottom)\n",
    "\n",
    "        # crop image\n",
    "        src_pts = np.array([[center[0]-size/2, center[1]-size/2], [center[0] - size/2, center[1]+size/2], [center[0]+size/2, center[1]-size/2]])\n",
    "        DST_PTS = np.array([[0,0], [0,self.resolution_inp - 1], [self.resolution_inp - 1, 0]])\n",
    "        tform = estimate_transform('similarity', src_pts, DST_PTS)\n",
    "        \n",
    "        image = image/255.\n",
    "        cropped_image = warp(image, tform.inverse, output_shape=(self.resolution_inp, self.resolution_inp))\n",
    "\n",
    "        # run our net\n",
    "        #st = time()\n",
    "        cropped_pos = self.net_forward(cropped_image)\n",
    "        #print 'net time:', time() - st\n",
    "\n",
    "        # restore \n",
    "        cropped_vertices = np.reshape(cropped_pos, [-1, 3]).T\n",
    "        z = cropped_vertices[2,:].copy()/tform.params[0,0]\n",
    "        cropped_vertices[2,:] = 1\n",
    "        vertices = np.dot(np.linalg.inv(tform.params), cropped_vertices)\n",
    "        vertices = np.vstack((vertices[:2,:], z))\n",
    "        pos = np.reshape(vertices.T, [self.resolution_op, self.resolution_op, 3])\n",
    "        \n",
    "        return pos,coor_face\n",
    "            \n",
    "    def get_landmarks(self, pos):\n",
    "        '''\n",
    "        Args:\n",
    "            pos: the 3D position map. shape = (256, 256, 3).\n",
    "        Returns:\n",
    "            kpt: 68 3D landmarks. shape = (68, 3).\n",
    "        '''\n",
    "        kpt = pos[self.uv_kpt_ind[1,:], self.uv_kpt_ind[0,:], :]\n",
    "        return kpt\n",
    "\n",
    "\n",
    "    def get_vertices(self, pos):\n",
    "        '''\n",
    "        Args:\n",
    "            pos: the 3D position map. shape = (256, 256, 3).\n",
    "        Returns:\n",
    "            vertices: the vertices(point cloud). shape = (num of points, 3). n is about 40K here.\n",
    "        '''\n",
    "        all_vertices = np.reshape(pos, [self.resolution_op**2, -1])\n",
    "        vertices = all_vertices[self.face_ind, :]\n",
    "\n",
    "        return vertices\n",
    "\n",
    "    def get_colors_from_texture(self, texture):\n",
    "        '''\n",
    "        Args:\n",
    "            texture: the texture map. shape = (256, 256, 3).\n",
    "        Returns:\n",
    "            colors: the corresponding colors of vertices. shape = (num of points, 3). n is 45128 here.\n",
    "        '''\n",
    "        all_colors = np.reshape(texture, [self.resolution_op**2, -1])\n",
    "        colors = all_colors[self.face_ind, :]\n",
    "\n",
    "        return colors\n",
    "\n",
    "\n",
    "    def get_colors(self, image, vertices):\n",
    "        '''\n",
    "        Args:\n",
    "            pos: the 3D position map. shape = (256, 256, 3).\n",
    "        Returns:\n",
    "            colors: the corresponding colors of vertices. shape = (num of points, 3). n is 45128 here.\n",
    "        '''\n",
    "        [h, w, _] = image.shape\n",
    "        vertices[:,0] = np.minimum(np.maximum(vertices[:,0], 0), w - 1)  # x\n",
    "        vertices[:,1] = np.minimum(np.maximum(vertices[:,1], 0), h - 1)  # y\n",
    "        ind = np.round(vertices).astype(np.int32)\n",
    "        colors = image[ind[:,1], ind[:,0], :] # n x 3\n",
    "\n",
    "        return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da01d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pr(options):\n",
    "    # init PRN\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(options['gpu']) # GPU number, -1 for CPU\n",
    "    prn = PRN(is_dlib = options['isDlib'])\n",
    "\n",
    "    # load data\n",
    "    save_folder = options['output']\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.mkdir(save_folder)\n",
    "        \n",
    "    if not os.path.exists(options['material']):\n",
    "        os.mkdir(options['material'])\n",
    "        \n",
    "    image_path_list = []\n",
    "    for pattern in ('*.jpg', '*.png'):\n",
    "        image_path_list.extend(glob(os.path.join(options['input'], pattern)))\n",
    "\n",
    "    total_num = len(image_path_list)\n",
    "    count_i = 1\n",
    "    for image_path in image_path_list:\n",
    "        name = image_path.strip().split(os.path.sep)[-1][:-4]\n",
    "        print(\"INFO: Image {}/{} - {} is processing.\".format(count_i, total_num, name))\n",
    "        count_i+=1\n",
    "\n",
    "        image = imread(image_path)\n",
    "        [h, w, c] = image.shape\n",
    "        img = np.zeros([image.shape[0], image.shape[1]]).astype(np.uint8)\n",
    "        if c > 3:\n",
    "            image = image[:,:,:3]        \n",
    "\n",
    "        # the core: regress position map\n",
    "        s_time = time()\n",
    "        if options['isDlib']:\n",
    "            max_size = max(image.shape[0], image.shape[1])\n",
    "            if max_size > 1000:\n",
    "                image = rescale(image, 1000./max_size)\n",
    "                image = (image * 255).astype(np.uint8)\n",
    "            pos, box = prn.process(image) # use dlib to detect face\n",
    "        else:\n",
    "            if image.shape[0] == image.shape[1]:\n",
    "                image = resize(image, (256,256))\n",
    "                pos = prn.net_forward(image/255.) # input image has been cropped to 256x256\n",
    "            else:\n",
    "                box = np.array([0, image.shape[1]-1, 0, image.shape[0]-1]) # cropped with bounding box\n",
    "                pos = prn.process(image, box)\n",
    "\n",
    "        image = image / 255.\n",
    "        if pos is None:\n",
    "            continue\n",
    "\n",
    "        if options['is3d'] or options['isMat'] or options['isPose'] or options['isShow']:\n",
    "            # 3D vertices\n",
    "            vertices = prn.get_vertices(pos)\n",
    "            if options['isFront']:\n",
    "                save_vertices = frontalize(vertices)\n",
    "            else:\n",
    "                save_vertices = vertices.copy()\n",
    "                \n",
    "            save_vertices[:,1] = h - 1 - save_vertices[:,1]\n",
    "\n",
    "        if options['isImage']:\n",
    "            imsave(os.path.join(save_folder, name + '.jpg'), image)\n",
    "\n",
    "        if options['is3d']:\n",
    "            # corresponding colors\n",
    "            colors = prn.get_colors(image, vertices)\n",
    "\n",
    "            if options['isTexture']:\n",
    "                if options['textureSize'] != 256:\n",
    "                    pos_interpolated = resize(pos, (options['textureSize'], options['textureSize']), preserve_range = True)\n",
    "                else:\n",
    "                    pos_interpolated = pos.copy()\n",
    "                    \n",
    "                texture = cv2.remap(image, pos_interpolated[:,:,:2].astype(np.float32), None, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(0))\n",
    "                if options['isMask']:\n",
    "                    vertices_vis = get_visibility(vertices, prn.triangles, h, w)\n",
    "                    uv_mask = get_uv_mask(vertices_vis, prn.triangles, prn.uv_coords, h, w, prn.resolution_op)\n",
    "                    uv_mask = resize(uv_mask, (options['textureSize'], options['textureSize']), preserve_range = True)\n",
    "                    texture = texture * uv_mask[:,:,np.newaxis]\n",
    "                    \n",
    "                # save 3d face with texture(can open with meshlab)\n",
    "                write_obj_with_texture(os.path.join(save_folder, name + '.obj'), save_vertices, prn.triangles, texture, prn.uv_coords/prn.resolution_op)\n",
    "            else:\n",
    "                # save 3d face(can open with meshlab)\n",
    "                write_obj_with_colors(os.path.join(save_folder, name + '.obj'), save_vertices, prn.triangles, colors)\n",
    "\n",
    "        if options['isDepth']:\n",
    "            depth_image = get_depth_image(vertices, prn.triangles, h, w, True)\n",
    "            depth = get_depth_image(vertices, prn.triangles, h, w)\n",
    "            try:\n",
    "                imsave(\n",
    "                    os.path.join(save_folder, name + '_depth.jpg'), \n",
    "                    cv2.normalize(depth_image, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "                )\n",
    "            except:\n",
    "                print('Cannot write depth face.')\n",
    "                \n",
    "            # sio.savemat(os.path.join(save_folder, name + '_depth.mat'), {'depth':depth})\n",
    "\n",
    "        if options['isMat']:\n",
    "            colors = prn.get_colors(image, vertices)\n",
    "            # coordinates=[h,w,x,y,w_x,h_y]\n",
    "            # np.savetxt(os.path.join(save_folder, name + '_coor.txt'), coor_face)\n",
    "            sio.savemat(os.path.join(options['material'], name + '_mesh.mat'), {'vertices': vertices, 'colors': colors, 'triangles': prn.triangles})\n",
    "\n",
    "        if options['isKpt'] or options['isShow']:\n",
    "            # get landmarks\n",
    "            kpt = prn.get_landmarks(pos)\n",
    "            # np.savetxt(os.path.join(save_folder, name + '_kpt.txt'), kpt)\n",
    "\n",
    "        if options['isPose'] or options['isShow']:\n",
    "            # estimate pose\n",
    "            camera_matrix, pose = estimate_pose(vertices)\n",
    "            # np.savetxt(os.path.join(save_folder, name + '_pose.txt'), pose) \n",
    "            # np.savetxt(os.path.join(save_folder, name + '_camera_matrix.txt'), camera_matrix) \n",
    "            # np.savetxt(os.path.join(save_folder, name + '_pose.txt'), pose)\n",
    "\n",
    "        if options['isShow']:\n",
    "            # Plot\n",
    "            image=(image * 255).astype(np.uint8)\n",
    "            point_cloud=plot_vertices(img, vertices)\n",
    "            point_cloud=point_cloud[y:h_y,x:w_x]\n",
    "            crop_image=image[y:h_y,x:w_x]\n",
    "            image_pose = plot_pose_box(image, camera_matrix, kpt)\n",
    "            imsave(os.path.join(save_folder, name + '_pose.jpg'),  plot_pose_box(image, camera_matrix, kpt))\n",
    "            imsave(os.path.join(save_folder, name + '_point.jpg'),  point_cloud)\n",
    "            imsave(os.path.join(save_folder, name + '_crop.jpg'),  crop_image)\n",
    "            imsave(os.path.join(save_folder, name + '_kpt.jpg'),  plot_kpt(image, kpt))\n",
    "            \n",
    "        e_time=time()\n",
    "        print('Time running: ', e_time-s_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e430879",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./data/net-data/256_256_resfcn256_weight\n",
      "INFO: Image 1/1 - inp is processing.\n",
      "Time running:  52.51709604263306\n"
     ]
    }
   ],
   "source": [
    "run_pr(PR_RUN_OPTIONS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
